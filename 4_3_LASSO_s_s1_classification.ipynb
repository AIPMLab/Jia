{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import rcParams\n",
    "\n",
    "# Set the global default font to Times New Roman\n",
    "rcParams['font.family'] = 'Times New Roman'\n",
    "\n",
    "# 1. Read the training and testing CSV files\n",
    "train_data = pd.read_csv(\"D:/Apple-paper/Radiomics/survival analysis/survival analysis/APPLE/t1+t1Gd+t2+flair/2_3_lasso_feature_divide_train_test/Total_GBM+LGG_T1+T2+T1GD+flair_s1_add_os_age_gender_label_train_selsect_lasso.csv\")\n",
    "test_data = pd.read_csv(\"D:/Apple-paper/Radiomics/survival analysis/survival analysis/APPLE/t1+t1Gd+t2+flair/2_3_lasso_feature_divide_train_test/Total_GBM+LGG_T1+T2+T1GD+flair_s1_add_os_age_gender_label_test_selsect_lasso.csv\")\n",
    "\n",
    "# 0. Remove irrelevant columns\n",
    "train_data = train_data.drop(['index', 'gender', 'age_at_index', 'OS', \"OS.time\"], axis=1)\n",
    "test_data = test_data.drop(['index', 'gender', 'age_at_index', 'OS', \"OS.time\"], axis=1)\n",
    "\n",
    "# 2. Separate features and labels\n",
    "X_train = train_data.drop('label', axis=1)\n",
    "y_train = train_data['label']\n",
    "X_test = test_data.drop('label', axis=1)\n",
    "y_test = test_data['label']\n",
    "\n",
    "# 3. Initialize and train the Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=300, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate AUC\n",
    "auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# 4. Evaluate the model using the test set\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "sensitivity = tp / (tp + fn)\n",
    "\n",
    "# 5. Plot the ROC curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % auc_score)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=36)\n",
    "plt.ylabel('True Positive Rate', fontsize=36)\n",
    "plt.title('Receiver Operating Characteristic', fontsize=36, y=1.02)\n",
    "plt.legend(loc=\"lower right\", prop={'size': 30})\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# 6. Plot the confusion matrix\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.set(font_scale=4)\n",
    "heatmap = sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', annot_kws={\"size\": 60})\n",
    "cbar = heatmap.collections[0].colorbar\n",
    "cbar.ax.tick_params(labelsize=36)\n",
    "plt.xlabel('Predicted labels', fontsize=36)\n",
    "plt.ylabel('True labels', fontsize=36)\n",
    "plt.show()\n",
    "\n",
    "# Calculate specificity\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "# Calculate precision\n",
    "precision = tp / (tp + fp)\n",
    "\n",
    "# 7. Output evaluation metrics\n",
    "print(\"AUC Score:\", auc_score)\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Specificity:\", specificity)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to calculate net benefit for the model\n",
    "def calculate_net_benefit(thresholds, y_true, y_proba):\n",
    "    net_benefits = []\n",
    "    for threshold in thresholds:\n",
    "        w = threshold / (1 - threshold)  # Weight for false positives\n",
    "        predictions = y_proba >= threshold  # Predictions based on the current threshold\n",
    "        tp = np.sum((predictions == 1) & (y_true == 1))  # True positives\n",
    "        fp = np.sum((predictions == 1) & (y_true == 0))  # False positives\n",
    "        net_benefit = tp - (fp * w)  # Calculate net benefit\n",
    "        net_benefits.append(net_benefit / len(y_true))\n",
    "    return net_benefits\n",
    "\n",
    "# Calculate net benefit for \"All\" treated (assumes all cases are positive)\n",
    "def net_benefit_all(thresholds, y_true):\n",
    "    prevalence = np.mean(y_true)\n",
    "    return [prevalence - (1 - prevalence) * (threshold / (1 - threshold)) for threshold in thresholds]\n",
    "\n",
    "# Calculate net benefit for \"None\" treated (assumes no cases are positive)\n",
    "def net_benefit_none(thresholds):\n",
    "    return [0 for _ in thresholds]\n",
    "\n",
    "# Range of thresholds from 0.01 to 0.99\n",
    "thresholds = np.linspace(0.01, 0.99, 100)\n",
    "\n",
    "# Calculate net benefits\n",
    "model_net_benefits = calculate_net_benefit(thresholds, y_test, y_pred_proba)\n",
    "all_net_benefits = net_benefit_all(thresholds, y_test)\n",
    "none_net_benefits = net_benefit_none(thresholds)\n",
    "\n",
    "# Plot Decision Curve Analysis\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(thresholds, model_net_benefits, label='RF', color='red')\n",
    "plt.plot(thresholds, all_net_benefits, label='Treat All', color='blue', linestyle='--')\n",
    "plt.plot(thresholds, none_net_benefits, label='Treat None', color='green', linestyle=':', linewidth=2)\n",
    "plt.xlabel('Probability Threshold', fontsize=16)\n",
    "plt.ylabel('Net Benefit', fontsize=16)\n",
    "plt.title('Decision Curve Analysis', fontsize=18)\n",
    "plt.legend(loc='lower left', fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([-0.1, 1])  # Adjust Y-axis to slightly below zero for visibility\n",
    "plt.show()\n",
    "\n",
    "print(\"Number of features used for training:\", X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix, roc_curve\n",
    "from matplotlib import rcParams\n",
    "\n",
    "# Set the global default font to Times New Roman\n",
    "rcParams['font.family'] = 'Times New Roman'\n",
    "\n",
    "# 1. Read the training and testing CSV files\n",
    "train_data = pd.read_csv(\"D:/Apple-paper/Radiomics/survival analysis/survival analysis/APPLE/t1+t1Gd+t2+flair/2_3_lasso_feature_divide_train_test/Total_GBM+LGG_T1+T2+T1GD+flair_s1_add_os_age_gender_label_train_selsect_lasso.csv\")\n",
    "test_data = pd.read_csv(\"D:/Apple-paper/Radiomics/survival analysis/survival analysis/APPLE/t1+t1Gd+t2+flair/2_3_lasso_feature_divide_train_test/Total_GBM+LGG_T1+T2+T1GD+flair_s1_add_os_age_gender_label_test_selsect_lasso.csv\")\n",
    "\n",
    "# 0. Remove irrelevant columns\n",
    "train_data = train_data.drop(['index', 'gender', 'age_at_index', 'OS', \"OS.time\"], axis=1)\n",
    "test_data = test_data.drop(['index', 'gender', 'age_at_index', 'OS', \"OS.time\"], axis=1)\n",
    "\n",
    "# 2. Separate features and labels\n",
    "x_train = train_data.drop('label', axis=1)\n",
    "y_train = train_data['label']\n",
    "x_test = test_data.drop('label', axis=1)\n",
    "y_test = test_data['label']\n",
    "\n",
    "# Initialize and train the XGBoost model\n",
    "clf_XGB = XGBClassifier(use_label_encoder=False)\n",
    "clf_XGB.fit(x_train, y_train)\n",
    "\n",
    "# Calculate predicted probabilities\n",
    "y_pred_proba = clf_XGB.predict_proba(x_test)[:, 1]\n",
    "\n",
    "# Calculate AUC\n",
    "auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# Calculate model evaluation metrics\n",
    "y_pred = clf_XGB.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "sensitivity = tp / (tp + fn)\n",
    "\n",
    "# 5. Plot the ROC curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % auc_score)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=36)\n",
    "plt.ylabel('True Positive Rate', fontsize=36)\n",
    "plt.title('Receiver Operating Characteristic', fontsize=36, y=1.02)\n",
    "plt.legend(loc=\"lower right\", prop={'size': 30})\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# 6. Plot the confusion matrix\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.set(font_scale=4)\n",
    "heatmap = sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', annot_kws={\"size\": 60})\n",
    "cbar = heatmap.collections[0].colorbar\n",
    "cbar.ax.tick_params(labelsize=36)\n",
    "plt.xlabel('Predicted labels', fontsize=36)\n",
    "plt.ylabel('True labels', fontsize=36)\n",
    "plt.show()\n",
    "\n",
    "# Calculate specificity\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "# Calculate precision\n",
    "precision = tp / (tp + fp)\n",
    "\n",
    "# Output model evaluation metrics\n",
    "print(\"AUC Score:\", auc_score)\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Specificity:\", specificity)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to calculate net benefit\n",
    "def calculate_net_benefit(tp, fp, total, threshold_prob):\n",
    "    if threshold_prob == 1:\n",
    "        return tp / total  # Handle the edge case when threshold_prob equals 1\n",
    "    else:\n",
    "        # Calculate the net benefit\n",
    "        benefit = tp - (fp * threshold_prob / (1 - threshold_prob))\n",
    "        return benefit / total\n",
    "\n",
    "# Function to perform Decision Curve Analysis (DCA)\n",
    "def decision_curve_analysis(y_true, y_pred_proba, thresholds=np.linspace(0, 1, 100)):\n",
    "    # Calculate true positives, false positives, and total instances\n",
    "    total = len(y_true)\n",
    "    net_benefits = []\n",
    "    for thresh in thresholds:\n",
    "        # Make predictions at the current threshold\n",
    "        y_pred = y_pred_proba >= thresh\n",
    "        tp = np.sum((y_pred == 1) & (y_true == 1))\n",
    "        fp = np.sum((y_pred == 1) & (y_true == 0))\n",
    "        # Calculate net benefit\n",
    "        nb = calculate_net_benefit(tp, fp, total, thresh)\n",
    "        net_benefits.append(nb)\n",
    "    return thresholds, net_benefits\n",
    "\n",
    "# Assume y_test and y_pred_proba are available from your previous code\n",
    "thresholds, net_benefits = decision_curve_analysis(y_test, y_pred_proba)\n",
    "\n",
    "# Plot Decision Curve Analysis\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(thresholds, net_benefits, label='XGBoost', color='red')\n",
    "plt.xlabel('Probability Threshold', fontsize=16)\n",
    "plt.ylabel('Net Benefit', fontsize=16)\n",
    "plt.title('Decision Curve Analysis', fontsize=18)\n",
    "plt.legend(loc='lower left', fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([-0.1, 1])  # Adjust Y-axis to slightly below zero for visibility\n",
    "plt.show()\n",
    "\n",
    "print(\"Number of features used for training:\", x_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression (LR)\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV  # Modification 1: Import GridSearchCV for hyperparameter tuning.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import rcParams\n",
    "from sklearn.preprocessing import StandardScaler  # Modification 2: Import StandardScaler for data normalization.\n",
    "\n",
    "# Set the global default font to Times New Roman\n",
    "rcParams['font.family'] = 'Times New Roman'\n",
    "\n",
    "# Read the training and testing CSV files\n",
    "train_data = pd.read_csv(\"D:/Apple-paper/Radiomics/survival analysis/survival analysis/APPLE/t1+t1Gd+t2+flair/2_3_lasso_feature_divide_train_test/Total_GBM+LGG_T1+T2+T1GD+flair_s1_add_os_age_gender_label_train_selsect_lasso.csv\")\n",
    "test_data = pd.read_csv(\"D:/Apple-paper/Radiomics/survival analysis/survival analysis/APPLE/t1+t1Gd+t2+flair/2_3_lasso_feature_divide_train_test/Total_GBM+LGG_T1+T2+T1GD+flair_s1_add_os_age_gender_label_test_selsect_lasso.csv\")\n",
    "\n",
    "# 0. Remove irrelevant columns\n",
    "train_data = train_data.drop(['index', 'gender', 'age_at_index', 'OS', \"OS.time\"], axis=1)\n",
    "test_data = test_data.drop(['index', 'gender', 'age_at_index', 'OS', \"OS.time\"], axis=1)\n",
    "\n",
    "# 2. Separate features and labels\n",
    "X_train = train_data.drop('label', axis=1)\n",
    "y_train = train_data['label']\n",
    "X_test = test_data.drop('label', axis=1)\n",
    "y_test = test_data['label']\n",
    "\n",
    "# 4. Data normalization (Modification 3: Add normalization step)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 5. Define the hyperparameter grid (Important modification)\n",
    "param_grid = {\n",
    "    'C': [1],  # Regularization strength\n",
    "    'solver': ['liblinear'],  # Optimization algorithm\n",
    "    'penalty': ['l2'],  # Regularization type\n",
    "    'max_iter': [100]  # Maximum number of iterations\n",
    "}\n",
    "\n",
    "# 6. Perform hyperparameter tuning using GridSearchCV (Important modification)\n",
    "model = LogisticRegression()\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 7. Retrieve the best model and its parameters\n",
    "best_model = grid_search.best_estimator_\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "\n",
    "# 8. Make predictions using the best model\n",
    "y_pred_proba = best_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Calculate AUC\n",
    "auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# 4. Evaluate the model using the test set\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "sensitivity = tp / (tp + fn)\n",
    "\n",
    "# 5. Plot the ROC curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % auc_score)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=36)\n",
    "plt.ylabel('True Positive Rate', fontsize=36)\n",
    "plt.title('Receiver Operating Characteristic', fontsize=36, y=1.02)\n",
    "plt.legend(loc=\"lower right\", prop={'size': 30})\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# 6. Plot the confusion matrix\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.set(font_scale=4)\n",
    "heatmap = sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', annot_kws={\"size\": 60})\n",
    "cbar = heatmap.collections[0].colorbar\n",
    "cbar.ax.tick_params(labelsize=36)\n",
    "plt.xlabel('Predicted labels', fontsize=36)\n",
    "plt.ylabel('True labels', fontsize=36)\n",
    "plt.show()\n",
    "\n",
    "# Calculate specificity\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "# Calculate precision\n",
    "precision = tp / (tp + fp)\n",
    "\n",
    "# 7. Output evaluation metrics\n",
    "print(\"AUC Score:\", auc_score)\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Specificity:\", specificity)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "# Function to calculate net benefit for the model\n",
    "def calculate_net_benefit(thresholds, y_true, y_proba):\n",
    "    net_benefits = []\n",
    "    for threshold in thresholds:\n",
    "        w = threshold / (1 - threshold)  # Weight for false positives\n",
    "        predictions = y_proba >= threshold  # Predictions based on the current threshold\n",
    "        tp = np.sum((predictions == 1) & (y_true == 1))  # True positives\n",
    "        fp = np.sum((predictions == 1) & (y_true == 0))  # False positives\n",
    "        net_benefit = tp - (fp * w)  # Calculate net benefit\n",
    "        net_benefits.append(net_benefit / len(y_true))\n",
    "    return net_benefits\n",
    "\n",
    "# Calculate net benefit for \"All\" treated (assumes all cases are positive)\n",
    "def net_benefit_all(thresholds, y_true):\n",
    "    prevalence = np.mean(y_true)\n",
    "    return [prevalence - (1 - prevalence) * (threshold / (1 - threshold)) for threshold in thresholds]\n",
    "\n",
    "# Calculate net benefit for \"None\" treated (assumes no cases are positive)\n",
    "def net_benefit_none(thresholds):\n",
    "    return [0 for _ in thresholds]\n",
    "\n",
    "# Range of thresholds from 0.01 to 0.99\n",
    "thresholds = np.linspace(0.01, 0.99, 100)\n",
    "\n",
    "# Calculate net benefits\n",
    "model_net_benefits = calculate_net_benefit(thresholds, y_test, y_pred_proba)\n",
    "all_net_benefits = net_benefit_all(thresholds, y_test)\n",
    "none_net_benefits = net_benefit_none(thresholds)\n",
    "\n",
    "# Plot Decision Curve Analysis\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(thresholds, model_net_benefits, label='LR', color='red')\n",
    "plt.plot(thresholds, all_net_benefits, label='Treat All', color='blue', linestyle='--')\n",
    "plt.plot(thresholds, none_net_benefits, label='Treat None', color='green', linestyle=':', linewidth=2)\n",
    "plt.xlabel('Probability Threshold', fontsize=16)\n",
    "plt.ylabel('Net Benefit', fontsize=16)\n",
    "plt.title('Decision Curve Analysis', fontsize=18)\n",
    "plt.legend(loc='lower left', fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([-0.1, 1])  # Adjust Y-axis to slightly below zero for visibility\n",
    "plt.show()\n",
    "\n",
    "print(\"Number of features used for training:\", X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV  # Correct import here\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from matplotlib import rcParams\n",
    "\n",
    "# Set the global default font to Times New Roman\n",
    "rcParams['font.family'] = 'Times New Roman'\n",
    "\n",
    "# Read the training and testing CSV files\n",
    "train_data = pd.read_csv(\"D:/Apple-paper/Radiomics/survival analysis/survival analysis/APPLE/t1+t1Gd+t2+flair/2_3_lasso_feature_divide_train_test/Total_GBM+LGG_T1+T2+T1GD+flair_s1_add_os_age_gender_label_train_selsect_lasso.csv\")\n",
    "test_data = pd.read_csv(\"D:/Apple-paper/Radiomics/survival analysis/survival analysis/APPLE/t1+t1Gd+t2+flair/2_3_lasso_feature_divide_train_test/Total_GBM+LGG_T1+T2+T1GD+flair_s1_add_os_age_gender_label_test_selsect_lasso.csv\")\n",
    "\n",
    "# 0. Remove irrelevant columns\n",
    "train_data = train_data.drop(['index', 'gender', 'age_at_index', 'OS', \"OS.time\"], axis=1)\n",
    "test_data = test_data.drop(['index', 'gender', 'age_at_index', 'OS', \"OS.time\"], axis=1)\n",
    "\n",
    "# 2. Separate features and labels\n",
    "X_train = train_data.drop('label', axis=1)\n",
    "y_train = train_data['label']\n",
    "X_test = test_data.drop('label', axis=1)\n",
    "y_test = test_data['label']\n",
    "\n",
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Use GridSearchCV to optimize SVC hyperparameters and handle class imbalance\n",
    "param_grid = {'C': [1], 'kernel': ['linear', 'rbf'], 'class_weight': [None, 'balanced']}\n",
    "model = GridSearchCV(SVC(probability=True), param_grid, cv=5, scoring='roc_auc')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Calculate AUC\n",
    "auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# 4. Evaluate the model using the test set\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "sensitivity = tp / (tp + fn)\n",
    "\n",
    "# Calculate specificity\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "# Calculate precision\n",
    "precision = tp / (tp + fp)\n",
    "\n",
    "# 5. Plot the ROC curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % auc_score)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=36)\n",
    "plt.ylabel('True Positive Rate', fontsize=36)\n",
    "plt.title('Receiver Operating Characteristic', fontsize=36, y=1.02)\n",
    "plt.legend(loc=\"lower right\", prop={'size': 30})\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# 6. Plot the confusion matrix\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.set(font_scale=4)\n",
    "heatmap = sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', annot_kws={\"size\": 60})\n",
    "cbar = heatmap.collections[0].colorbar\n",
    "cbar.ax.tick_params(labelsize=36)\n",
    "plt.xlabel('Predicted labels', fontsize=36)\n",
    "plt.ylabel('True labels', fontsize=36)\n",
    "plt.show()\n",
    "\n",
    "# 7. Output evaluation metrics\n",
    "print(\"AUC Score:\", auc_score)\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Confusion Matrix:\", conf_matrix)\n",
    "print(\"Specificity:\", specificity)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "# Function to calculate net benefit for the model\n",
    "def calculate_net_benefit(thresholds, y_true, y_proba):\n",
    "    net_benefits = []\n",
    "    for threshold in thresholds:\n",
    "        w = threshold / (1 - threshold)  # Weight for false positives\n",
    "        predictions = y_proba >= threshold  # Predictions based on the current threshold\n",
    "        tp = np.sum((predictions == 1) & (y_true == 1))  # True positives\n",
    "        fp = np.sum((predictions == 1) & (y_true == 0))  # False positives\n",
    "        net_benefit = tp - (fp * w)  # Calculate net benefit\n",
    "        net_benefits.append(net_benefit / len(y_true))\n",
    "    return net_benefits\n",
    "\n",
    "# Calculate net benefit for \"All\" treated (assumes all cases are positive)\n",
    "def net_benefit_all(thresholds, y_true):\n",
    "    prevalence = np.mean(y_true)\n",
    "    return [prevalence - (1 - prevalence) * (threshold / (1 - threshold)) for threshold in thresholds]\n",
    "\n",
    "# Calculate net benefit for \"None\" treated (assumes no cases are positive)\n",
    "def net_benefit_none(thresholds):\n",
    "    return [0 for _ in thresholds]\n",
    "\n",
    "# Range of thresholds from 0.01 to 0.99\n",
    "thresholds = np.linspace(0.01, 0.99, 100)\n",
    "\n",
    "# Calculate net benefits\n",
    "model_net_benefits = calculate_net_benefit(thresholds, y_test, y_pred_proba)\n",
    "all_net_benefits = net_benefit_all(thresholds, y_test)\n",
    "none_net_benefits = net_benefit_none(thresholds)\n",
    "\n",
    "# Plot Decision Curve Analysis\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(thresholds, model_net_benefits, label='SVM', color='red')\n",
    "plt.plot(thresholds, all_net_benefits, label='Treat All', color='blue', linestyle='--')\n",
    "plt.plot(thresholds, none_net_benefits, label='Treat None', color='green', linestyle=':', linewidth=2)\n",
    "plt.xlabel('Probability Threshold', fontsize=16)\n",
    "plt.ylabel('Net Benefit', fontsize=16)\n",
    "plt.title('Decision Curve Analysis', fontsize=18)\n",
    "plt.legend(loc='lower left', fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([-0.1, 1])  # Adjust Y-axis to slightly below zero for visibility\n",
    "plt.show()\n",
    "\n",
    "print(\"Number of features used for training:\", X_train.shape[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
