{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#随机森林\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import rcParams\n",
    "# 设置全局默认字体为Times New Roman\n",
    "rcParams['font.family'] = 'Times New Roman'\n",
    "# 1. 读取训练集和测试集CSV文件\n",
    "train_data = pd.read_csv(\"D:/Apple-paper/Radiomics/survival analysis/survival analysis/APPLE/t1+t1Gd+t2+flair/2_2_all_feature_divide_train_test/Total_GBM+LGG_t1+t2+t2Gd+flair_s1_all_feature_train_icc.csv\")\n",
    "test_data = pd.read_csv(\"D:/Apple-paper/Radiomics/survival analysis/survival analysis/APPLE/t1+t1Gd+t2+flair/2_2_all_feature_divide_train_test/Total_GBM+LGG_t1+t2+t2Gd+flair_s1_all_feature_test_icc.csv\")\n",
    "#0去除index\n",
    "train_data = train_data.drop(['index','gender','age_at_index','OS',\"OS.time\"], axis=1)\n",
    "test_data = test_data.drop(['index','gender','age_at_index','OS',\"OS.time\"], axis=1)\n",
    "# 2. 分离特征和标签\n",
    "X_train = train_data.drop('label', axis=1)\n",
    "y_train = train_data['label']\n",
    "X_test = test_data.drop('label', axis=1)\n",
    "y_test = test_data['label']\n",
    "\n",
    "# 3. 初始化并训练随机森林模型\n",
    "model = RandomForestClassifier(n_estimators=300, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "# 计算AUC\n",
    "auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "# 4. 使用测试集评估模型\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "# auc_score = roc_auc_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "sensitivity = tp / (tp + fn)\n",
    "\n",
    "# 5. 绘制ROC曲线\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % auc_score)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=36)\n",
    "plt.ylabel('True Positive Rate', fontsize=36)\n",
    "plt.title('Receiver Operating Characteristic', fontsize=36, y=1.02)\n",
    "plt.legend(loc=\"lower right\", prop={'size': 30})\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\")\n",
    "# 6. 绘制混淆矩阵\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.set(font_scale=4)\n",
    "heatmap = sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', annot_kws={\"size\": 60})#中间\n",
    "cbar = heatmap.collections[0].colorbar\n",
    "cbar.ax.tick_params(labelsize=36)\n",
    "plt.xlabel('Predicted labels', fontsize=36)\n",
    "plt.ylabel('True labels', fontsize=36)\n",
    "# plt.title('ICC feature-Random forest', fontsize=36, y=1.02)  # 调整标题位置\n",
    "plt.show()\n",
    "# 计算 specificity\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "# 计算 precision\n",
    "precision = tp / (tp + fp)\n",
    "# 7. 输出评估指标\n",
    "print(\"AUC Score:\", auc_score)\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "print(\"Specificity:\", specificity)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to calculate net benefit for the model\n",
    "def calculate_net_benefit(thresholds, y_true, y_proba):\n",
    "    net_benefits = []\n",
    "    for threshold in thresholds:\n",
    "        w = threshold / (1 - threshold)  # Weight for false positives\n",
    "        predictions = y_proba >= threshold  # Predictions based on the current threshold\n",
    "        tp = np.sum((predictions == 1) & (y_true == 1))  # True positives\n",
    "        fp = np.sum((predictions == 1) & (y_true == 0))  # False positives\n",
    "        net_benefit = tp - (fp * w)  # Calculate net benefit\n",
    "        net_benefits.append(net_benefit / len(y_true))\n",
    "    return net_benefits\n",
    "\n",
    "# Calculate net benefit for \"All\" treated (assumes all cases are positive)\n",
    "def net_benefit_all(thresholds, y_true):\n",
    "    prevalence = np.mean(y_true)\n",
    "    return [prevalence - (1 - prevalence) * (threshold / (1 - threshold)) for threshold in thresholds]\n",
    "\n",
    "# Calculate net benefit for \"None\" treated (assumes no cases are positive)\n",
    "def net_benefit_none(thresholds):\n",
    "    return [0 for _ in thresholds]\n",
    "\n",
    "# Range of thresholds from 0.01 to 0.99\n",
    "thresholds = np.linspace(0.01, 0.99, 100)\n",
    "\n",
    "# Calculate net benefits\n",
    "model_net_benefits = calculate_net_benefit(thresholds, y_test, y_pred_proba)\n",
    "all_net_benefits = net_benefit_all(thresholds, y_test)\n",
    "none_net_benefits = net_benefit_none(thresholds)\n",
    "\n",
    "# Plot Decision Curve Analysis\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(thresholds, model_net_benefits, label='RF', color='red')\n",
    "plt.plot(thresholds, all_net_benefits, label='Treat All', color='blue', linestyle='--')\n",
    "plt.plot(thresholds, none_net_benefits, label='Treat None', color='green', linestyle=':', linewidth=2)\n",
    "plt.xlabel('Probability Threshold', fontsize=16)\n",
    "plt.ylabel('Net Benefit', fontsize=16)\n",
    "plt.title('Decision Curve Analysis', fontsize=18)\n",
    "plt.legend(loc='lower left', fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([-0.1, 1])  # Adjust Y-axis to slightly below zero for visibility\n",
    "plt.show()\n",
    "print(\"Number of features used for training:\", X_train.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgboost\n",
    "from xgboost import XGBClassifier\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix, roc_curve\n",
    "from matplotlib import rcParams\n",
    "# 设置全局默认字体为Times New Roman\n",
    "rcParams['font.family'] = 'Times New Roman'\n",
    "# 1. 读取训练集和测试集CSV文件\n",
    "train_data = pd.read_csv(\"D:/Apple-paper/Radiomics/survival analysis/survival analysis/APPLE/t1+t1Gd+t2+flair/2_2_all_feature_divide_train_test/Total_GBM+LGG_t1+t2+t2Gd+flair_s1_all_feature_train_icc.csv\")\n",
    "test_data = pd.read_csv(\"D:/Apple-paper/Radiomics/survival analysis/survival analysis/APPLE/t1+t1Gd+t2+flair/2_2_all_feature_divide_train_test/Total_GBM+LGG_t1+t2+t2Gd+flair_s1_all_feature_test_icc.csv\")\n",
    "#0去除index\n",
    "train_data = train_data.drop(['index','gender','age_at_index','OS',\"OS.time\"], axis=1)\n",
    "test_data = test_data.drop(['index','gender','age_at_index','OS',\"OS.time\"], axis=1)\n",
    "# 2. 分离特征和标签\n",
    "x_train = train_data.drop('label', axis=1)\n",
    "y_train = train_data['label']\n",
    "x_test = test_data.drop('label', axis=1)\n",
    "y_test = test_data['label']\n",
    "clf_XGB = XGBClassifier(use_label_encoder=False)\n",
    "clf_XGB.fit(x_train, y_train)\n",
    "# 计算预测概率\n",
    "y_pred_proba = clf_XGB.predict_proba(x_test)[:, 1]\n",
    "\n",
    "# 计算AUC\n",
    "auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# 计算模型评估指标\n",
    "y_pred = clf_XGB.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "# auc_score = roc_auc_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "sensitivity = tp / (tp + fn)\n",
    "\n",
    "# 5. 绘制ROC曲线\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % auc_score)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=36)\n",
    "plt.ylabel('True Positive Rate', fontsize=36)\n",
    "plt.title('Receiver Operating Characteristic', fontsize=36, y=1.02)\n",
    "plt.legend(loc=\"lower right\", prop={'size': 30})\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\")\n",
    "# 6. 绘制混淆矩阵\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.set(font_scale=4)\n",
    "heatmap = sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', annot_kws={\"size\": 60})#中间\n",
    "cbar = heatmap.collections[0].colorbar\n",
    "cbar.ax.tick_params(labelsize=36)\n",
    "plt.xlabel('Predicted labels', fontsize=36)\n",
    "plt.ylabel('True labels', fontsize=36)\n",
    "# plt.title('ICC feature-Xgboost', fontsize=36, y=1.02)  # 调整标题位置\n",
    "plt.show()\n",
    "# 计算 specificity\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "# 计算 precision\n",
    "precision = tp / (tp + fp)\n",
    "# 输出模型评估指标\n",
    "print(\"AUC Score:\", auc_score)\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "# print(\"AUC Score:\", auc_score)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Specificity:\", specificity)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def calculate_net_benefit(tp, fp, total, threshold_prob):\n",
    "    if threshold_prob == 1:\n",
    "        return tp / total  # Handle the edge case when threshold_prob equals 1\n",
    "    else:\n",
    "        # Calculate the net benefit\n",
    "        benefit = tp - (fp * threshold_prob / (1 - threshold_prob))\n",
    "        return benefit / total\n",
    "    # # Calculate the net benefit\n",
    "    # benefit = tp - (fp * threshold_prob / (1 - threshold_prob))\n",
    "    # return benefit / total\n",
    "\n",
    "def decision_curve_analysis(y_true, y_pred_proba, thresholds=np.linspace(0, 1, 100)):\n",
    "    # Calculate true positives, false positives, and total instances\n",
    "    total = len(y_true)\n",
    "    net_benefits = []\n",
    "    for thresh in thresholds:\n",
    "        # Make predictions at the current threshold\n",
    "        y_pred = y_pred_proba >= thresh\n",
    "        tp = np.sum((y_pred == 1) & (y_true == 1))\n",
    "        fp = np.sum((y_pred == 1) & (y_true == 0))\n",
    "        # Calculate net benefit\n",
    "        nb = calculate_net_benefit(tp, fp, total, thresh)\n",
    "        net_benefits.append(nb)\n",
    "    return thresholds, net_benefits\n",
    "\n",
    "# Assume y_test and y_pred_proba are available from your previous code\n",
    "thresholds, net_benefits = decision_curve_analysis(y_test, y_pred_proba)\n",
    "\n",
    "# # Plot Decision Curve Analysis\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(thresholds, model_net_benefits, label='xgboost', color='red')\n",
    "plt.plot(thresholds, all_net_benefits, label='Treat All', color='blue', linestyle='--')\n",
    "plt.plot(thresholds, none_net_benefits, label='Treat None', color='green', linestyle=':', linewidth=2)\n",
    "plt.xlabel('Probability Threshold', fontsize=16)\n",
    "plt.ylabel('Net Benefit', fontsize=16)\n",
    "plt.title('Decision Curve Analysis', fontsize=18)\n",
    "plt.legend(loc='lower left', fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([-0.1, 1])  # Adjust Y-axis to slightly below zero for visibility\n",
    "plt.show()\n",
    "print(\"Number of features used for training:\", X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LR\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV #修改1\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import rcParams\n",
    "from sklearn.preprocessing import StandardScaler  # 修改2：导入标准化工具\n",
    "# 设置全局默认字体为Times New Roman\n",
    "rcParams['font.family'] = 'Times New Roman'\n",
    "train_data = pd.read_csv(\"D:/Apple-paper/Radiomics/survival analysis/survival analysis/APPLE/t1+t1Gd+t2+flair/2_2_all_feature_divide_train_test/Total_GBM+LGG_t1+t2+t2Gd+flair_s1_all_feature_train_icc.csv\")\n",
    "test_data = pd.read_csv(\"D:/Apple-paper/Radiomics/survival analysis/survival analysis/APPLE/t1+t1Gd+t2+flair/2_2_all_feature_divide_train_test/Total_GBM+LGG_t1+t2+t2Gd+flair_s1_all_feature_test_icc.csv\")\n",
    "#0去除index\n",
    "train_data = train_data.drop(['index','gender','age_at_index','OS',\"OS.time\"], axis=1)\n",
    "test_data = test_data.drop(['index','gender','age_at_index','OS',\"OS.time\"], axis=1)\n",
    "# 2. 分离特征和标签\n",
    "X_train = train_data.drop('label', axis=1)\n",
    "y_train = train_data['label']\n",
    "X_test = test_data.drop('label', axis=1)\n",
    "y_test = test_data['label']\n",
    "\n",
    "# 4. 数据标准化 (修改3：新增标准化步骤)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# # 3. 初始化并训练逻辑回归模型\n",
    "# model = LogisticRegression(penalty=\"l2\",solver=\"liblinear\",C=1.0,max_iter=100)\n",
    "# model.fit(X_train, y_train)\n",
    "# y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "\n",
    "# 5. 定义超参数网格 (重要修改)\n",
    "param_grid = {\n",
    "    'C': [1],  # 正则化强度\n",
    "    'solver': ['liblinear'],  # 选择优化算法\n",
    "    'penalty': ['l2'],  # 正则化类型\n",
    "    'max_iter': [100]  # 最大迭代次数\n",
    "}\n",
    "\n",
    "# 6. 使用GridSearchCV进行超参数调优 (重要修改)\n",
    "model = LogisticRegression()\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 7. 获取最优模型及其参数\n",
    "best_model = grid_search.best_estimator_\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "\n",
    "# 8. 用最优模型进行预测\n",
    "y_pred_proba = best_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# 计算AUC\n",
    "auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "# 4. 使用测试集评估模型\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "# auc_score = roc_auc_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "sensitivity = tp / (tp + fn)\n",
    "\n",
    "# 5. 绘制ROC曲线\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % auc_score)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=36)\n",
    "plt.ylabel('True Positive Rate', fontsize=36)\n",
    "plt.title('Receiver Operating Characteristic', fontsize=36, y=1.02)\n",
    "plt.legend(loc=\"lower right\", prop={'size': 30})\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\")\n",
    "# 6. 绘制混淆矩阵\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.set(font_scale=4)\n",
    "heatmap = sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', annot_kws={\"size\": 60})#中间\n",
    "cbar = heatmap.collections[0].colorbar\n",
    "cbar.ax.tick_params(labelsize=36)\n",
    "plt.xlabel('Predicted labels', fontsize=36)\n",
    "plt.ylabel('True labels', fontsize=36)\n",
    "# plt.title('ICC feature-Logistic regression', fontsize=36, y=1.02)  # 调整标题位置\n",
    "plt.show()\n",
    "# 计算 specificity\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "# 计算 precision\n",
    "precision = tp / (tp + fp)\n",
    "# 7. 输出评估指标\n",
    "print(\"AUC Score:\", auc_score)\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "print(\"Specificity:\", specificity)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "\n",
    "# import numpy as np\n",
    "\n",
    "# def calculate_net_benefit(tp, fp, threshold, num_cases):\n",
    "#     \"\"\"\n",
    "#     Calculate the net benefit for a given threshold.\n",
    "\n",
    "#     Args:\n",
    "#     tp (int): True positives.\n",
    "#     fp (int): False positives.\n",
    "#     threshold (float): Threshold probability.\n",
    "#     num_cases (int): Total number of cases.\n",
    "\n",
    "#     Returns:\n",
    "#     float: Net benefit.\n",
    "#     \"\"\"\n",
    "#     return (tp / num_cases) - (fp / num_cases) * (threshold / (1 - threshold))\n",
    "\n",
    "# def decision_curve_analysis(y_true, y_pred_proba, thresholds):\n",
    "#     \"\"\"\n",
    "#     Perform decision curve analysis.\n",
    "\n",
    "#     Args:\n",
    "#     y_true (array-like): True labels.\n",
    "#     y_pred_proba (array-like): Predicted probabilities.\n",
    "#     thresholds (array-like): Range of threshold probabilities.\n",
    "\n",
    "#     Returns:\n",
    "#     array-like: Net benefits for each threshold.\n",
    "#     \"\"\"\n",
    "#     num_cases = len(y_true)\n",
    "#     net_benefits = []\n",
    "#     for threshold in thresholds:\n",
    "#         y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "#         tp = np.sum((y_pred == 1) & (y_true == 1))\n",
    "#         fp = np.sum((y_pred == 1) & (y_true == 0))\n",
    "#         net_benefit = calculate_net_benefit(tp, fp, threshold, num_cases)\n",
    "#         net_benefits.append(net_benefit)\n",
    "#     return net_benefits\n",
    "\n",
    "# # Usage\n",
    "# thresholds = np.linspace(0, 1, 100)  # Define a range of threshold probabilities\n",
    "# dca_values = decision_curve_analysis(y_test, y_pred_proba, thresholds)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to calculate net benefit for the model\n",
    "def calculate_net_benefit(thresholds, y_true, y_proba):\n",
    "    net_benefits = []\n",
    "    for threshold in thresholds:\n",
    "        w = threshold / (1 - threshold)  # Weight for false positives\n",
    "        predictions = y_proba >= threshold  # Predictions based on the current threshold\n",
    "        tp = np.sum((predictions == 1) & (y_true == 1))  # True positives\n",
    "        fp = np.sum((predictions == 1) & (y_true == 0))  # False positives\n",
    "        net_benefit = tp - (fp * w)  # Calculate net benefit\n",
    "        net_benefits.append(net_benefit / len(y_true))\n",
    "    return net_benefits\n",
    "\n",
    "# Calculate net benefit for \"All\" treated (assumes all cases are positive)\n",
    "def net_benefit_all(thresholds, y_true):\n",
    "    prevalence = np.mean(y_true)\n",
    "    return [prevalence - (1 - prevalence) * (threshold / (1 - threshold)) for threshold in thresholds]\n",
    "\n",
    "# Calculate net benefit for \"None\" treated (assumes no cases are positive)\n",
    "def net_benefit_none(thresholds):\n",
    "    return [0 for _ in thresholds]\n",
    "\n",
    "# Range of thresholds from 0.01 to 0.99\n",
    "thresholds = np.linspace(0.01, 0.99, 100)\n",
    "\n",
    "# Calculate net benefits\n",
    "model_net_benefits = calculate_net_benefit(thresholds, y_test, y_pred_proba)\n",
    "all_net_benefits = net_benefit_all(thresholds, y_test)\n",
    "none_net_benefits = net_benefit_none(thresholds)\n",
    "\n",
    "# # Plot Decision Curve Analysis\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# plt.plot(thresholds, dca_values, color='green', lw=2, label='Decision Curve Analysis')\n",
    "# plt.xlabel('Threshold Probability', fontsize=20)\n",
    "# plt.ylabel('Net Benefit', fontsize=20)\n",
    "# plt.title('Decision Curve Analysis', fontsize=12, y=1.02)\n",
    "# plt.legend(loc=\"upper right\", fontsize=20)\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n",
    "# Plot Decision Curve Analysis\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(thresholds, model_net_benefits, label='LR', color='red')\n",
    "plt.plot(thresholds, all_net_benefits, label='Treat All', color='blue', linestyle='--')\n",
    "plt.plot(thresholds, none_net_benefits, label='Treat None', color='green', linestyle=':', linewidth=2)\n",
    "plt.xlabel('Probability Threshold', fontsize=16)\n",
    "plt.ylabel('Net Benefit', fontsize=16)\n",
    "plt.title('Decision Curve Analysis', fontsize=18)\n",
    "plt.legend(loc='lower left', fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([-0.1, 1])  # Adjust Y-axis to slightly below zero for visibility\n",
    "plt.show()\n",
    "print(\"Number of features used for training:\", X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#svm\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV  # Correct import here\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from matplotlib import rcParams\n",
    "# 设置全局默认字体为Times New Roman\n",
    "rcParams['font.family'] = 'Times New Roman'\n",
    "train_data = pd.read_csv(\"D:/Apple-paper/Radiomics/survival analysis/survival analysis/APPLE/t1+t1Gd+t2+flair/2_2_all_feature_divide_train_test/Total_GBM+LGG_t1+t2+t2Gd+flair_s1_all_feature_train.csv\")\n",
    "test_data = pd.read_csv(\"D:/Apple-paper/Radiomics/survival analysis/survival analysis/APPLE/t1+t1Gd+t2+flair/2_2_all_feature_divide_train_test/Total_GBM+LGG_t1+t2+t2Gd+flair_s1_all_feature_test.csv\")\n",
    "#0去除index\n",
    "train_data = train_data.drop(['index','gender','age_at_index','OS',\"OS.time\"], axis=1)\n",
    "test_data = test_data.drop(['index','gender','age_at_index','OS',\"OS.time\"], axis=1)\n",
    "# 2. 分离特征和标签\n",
    "X_train = train_data.drop('label', axis=1)\n",
    "y_train = train_data['label']\n",
    "X_test = test_data.drop('label', axis=1)\n",
    "y_test = test_data['label']\n",
    "# # 3. 初始化并训练支持向量机模型\n",
    "# # model = SVC(probability=True)\n",
    "# model = SVC(kernel='rbf', C=1.0,probability=True)\n",
    "# model.fit(X_train, y_train)\n",
    "# y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# 使用 GridSearchCV 来优化 SVC 的超参数，并考虑类别不平衡问题\n",
    "param_grid = {'C': [1], 'kernel': ['linear', 'rbf'], 'class_weight': [None, 'balanced']}\n",
    "model = GridSearchCV(SVC(probability=True), param_grid, cv=5, scoring='roc_auc')\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Best parameters found: \", model.best_params_)\n",
    "# 计算AUC\n",
    "auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "# 4. 使用测试集评估模型\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "# auc_score = roc_auc_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "sensitivity = tp / (tp + fn)\n",
    "\n",
    "# 计算 specificity\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "# 计算 precision\n",
    "precision = tp / (tp + fp)\n",
    "# 5. 绘制ROC曲线\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % auc_score)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=36)\n",
    "plt.ylabel('True Positive Rate', fontsize=36)\n",
    "plt.title('Receiver Operating Characteristic', fontsize=36, y=1.02)\n",
    "plt.legend(loc=\"lower right\", prop={'size': 30})\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\")\n",
    "# 6. 绘制混淆矩阵\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.set(font_scale=4)\n",
    "heatmap = sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', annot_kws={\"size\": 60})#中间\n",
    "cbar = heatmap.collections[0].colorbar\n",
    "cbar.ax.tick_params(labelsize=36)\n",
    "plt.xlabel('Predicted labels', fontsize=36)\n",
    "plt.ylabel('True labels', fontsize=36)\n",
    "# plt.title('ICC feature-Support vector machine', fontsize=36, y=1.02)  # 调整标题位置\n",
    "plt.show()\n",
    "# 7. 输出评估指标\n",
    "print(\"AUC Score:\", auc_score)\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Confusion Matrix:\", conf_matrix)\n",
    "\n",
    "\n",
    "print(\"Specificity:\", specificity)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "# import numpy as np\n",
    "\n",
    "# def calculate_net_benefit(tp, fp, threshold, num_cases):\n",
    "#     \"\"\"\n",
    "#     Calculate the net benefit for a given threshold.\n",
    "\n",
    "#     Args:\n",
    "#     tp (int): True positives.\n",
    "#     fp (int): False positives.\n",
    "#     threshold (float): Threshold probability.\n",
    "#     num_cases (int): Total number of cases.\n",
    "\n",
    "#     Returns:\n",
    "#     float: Net benefit.\n",
    "#     \"\"\"\n",
    "#     return (tp / num_cases) - (fp / num_cases) * (threshold / (1 - threshold))\n",
    "\n",
    "# def decision_curve_analysis(y_true, y_pred_proba, thresholds):\n",
    "#     \"\"\"\n",
    "#     Perform decision curve analysis.\n",
    "\n",
    "#     Args:\n",
    "#     y_true (array-like): True labels.\n",
    "#     y_pred_proba (array-like): Predicted probabilities.\n",
    "#     thresholds (array-like): Range of threshold probabilities.\n",
    "\n",
    "#     Returns:\n",
    "#     array-like: Net benefits for each threshold.\n",
    "#     \"\"\"\n",
    "#     num_cases = len(y_true)\n",
    "#     net_benefits = []\n",
    "#     for threshold in thresholds:\n",
    "#         y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "#         tp = np.sum((y_pred == 1) & (y_true == 1))\n",
    "#         fp = np.sum((y_pred == 1) & (y_true == 0))\n",
    "#         net_benefit = calculate_net_benefit(tp, fp, threshold, num_cases)\n",
    "#         net_benefits.append(net_benefit)\n",
    "#     return net_benefits\n",
    "\n",
    "# # Usage\n",
    "# thresholds = np.linspace(0, 1, 100)  # Define a range of threshold probabilities\n",
    "# dca_values = decision_curve_analysis(y_test, y_pred_proba, thresholds)\n",
    "\n",
    "# # Plot Decision Curve Analysis\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# plt.plot(thresholds, dca_values, color='green', lw=2, label='Decision Curve Analysis')\n",
    "# plt.xlabel('Threshold Probability', fontsize=20)\n",
    "# plt.ylabel('Net Benefit', fontsize=20)\n",
    "# plt.title('Decision Curve Analysis', fontsize=12, y=1.02)\n",
    "# plt.legend(loc=\"upper right\", fontsize=20)\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to calculate net benefit for the model\n",
    "def calculate_net_benefit(thresholds, y_true, y_proba):\n",
    "    net_benefits = []\n",
    "    for threshold in thresholds:\n",
    "        w = threshold / (1 - threshold)  # Weight for false positives\n",
    "        predictions = y_proba >= threshold  # Predictions based on the current threshold\n",
    "        tp = np.sum((predictions == 1) & (y_true == 1))  # True positives\n",
    "        fp = np.sum((predictions == 1) & (y_true == 0))  # False positives\n",
    "        net_benefit = tp - (fp * w)  # Calculate net benefit\n",
    "        net_benefits.append(net_benefit / len(y_true))\n",
    "    return net_benefits\n",
    "\n",
    "# Calculate net benefit for \"All\" treated (assumes all cases are positive)\n",
    "def net_benefit_all(thresholds, y_true):\n",
    "    prevalence = np.mean(y_true)\n",
    "    return [prevalence - (1 - prevalence) * (threshold / (1 - threshold)) for threshold in thresholds]\n",
    "\n",
    "# Calculate net benefit for \"None\" treated (assumes no cases are positive)\n",
    "def net_benefit_none(thresholds):\n",
    "    return [0 for _ in thresholds]\n",
    "\n",
    "# Range of thresholds from 0.01 to 0.99\n",
    "thresholds = np.linspace(0.01, 0.99, 100)\n",
    "\n",
    "# Calculate net benefits\n",
    "model_net_benefits = calculate_net_benefit(thresholds, y_test, y_pred_proba)\n",
    "all_net_benefits = net_benefit_all(thresholds, y_test)\n",
    "none_net_benefits = net_benefit_none(thresholds)\n",
    "\n",
    "\n",
    "# Plot Decision Curve Analysis\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(thresholds, model_net_benefits, label='RF', color='red')\n",
    "plt.plot(thresholds, all_net_benefits, label='Treat All', color='blue', linestyle='--')\n",
    "plt.plot(thresholds, none_net_benefits, label='Treat None', color='green', linestyle=':', linewidth=2)\n",
    "plt.xlabel('Probability Threshold', fontsize=16)\n",
    "plt.ylabel('Net Benefit', fontsize=16)\n",
    "plt.title('Decision Curve Analysis', fontsize=18)\n",
    "plt.legend(loc='lower left', fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([-0.1, 1])  # Adjust Y-axis to slightly below zero for visibility\n",
    "plt.show()\n",
    "print(\"Number of features used for training:\", X_train.shape[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
