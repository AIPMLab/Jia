{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RF\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lifelines import KaplanMeierFitter, CoxPHFitter\n",
    "from lifelines.plotting import add_at_risk_counts\n",
    "from lifelines.statistics import logrank_test\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from lifelines.utils import concordance_index\n",
    "\n",
    "# Function to load data\n",
    "def load_data():\n",
    "    train_data = pd.read_csv(\"D:/Apple/survival analysis/survival analysis/APPLE/t1+t1Gd+t2+flair/combination_survival/Total_GBM+LGG_t1+t2+t2Gd+flair_s_ICC_LASSO_survival_train.csv\")\n",
    "    test_data = pd.read_csv(\"D:/Apple/survival analysis/survival analysis/APPLE/t1+t1Gd+t2+flair/combination_survival/Total_GBM+LGG_t1+t2+t2Gd+flair_s_ICC_LASSO_survival_test.csv\")\n",
    "    return train_data, test_data\n",
    "# Define `load_data` function to load training and testing datasets from specified file paths.\n",
    " \n",
    "# Function to prepare data\n",
    "# def prepare_data(train_data, test_data):\n",
    "#     X_train = train_data.drop(columns=['index','age_at_index','gender'])\n",
    "#     y_train = train_data['OS']\n",
    "#     X_test = test_data.drop(columns=['index','age_at_index','gender'])\n",
    "#     return X_train, y_train, X_test\n",
    "#Function to prepare data\n",
    "def prepare_data(train_data, test_data):\n",
    "    X_train = train_data.drop(columns=['OS.time', 'OS', 'index','age_at_index','gender'])\n",
    "    y_train = train_data['OS']\n",
    "    X_test = test_data.drop(columns=['OS.time', 'OS', 'index','age_at_index','gender'])\n",
    "    return X_train, y_train, X_test\n",
    "# Define `prepare_data` function to extract features and labels from training and testing datasets:\n",
    "# - Drop irrelevant columns (e.g., `OS.time`, `index`, etc.).\n",
    "# - Return training features, training labels, and testing features.\n",
    "\n",
    "# Function to train Random Forest classifier\n",
    "def train_classifier(X_train, y_train):\n",
    "    model = RandomForestClassifier(n_estimators=300, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "# Define `train_classifier` function to train a Random Forest classifier:\n",
    "# - `n_estimators=300` specifies the number of trees in the forest.\n",
    "# - Return the trained model.\n",
    "\n",
    "# Function to predict and assign survival groups\n",
    "def assign_survival_groups(model, train_data, test_data):\n",
    "    # Combine train and test data\n",
    "    combined_data = pd.concat([train_data, test_data], axis=0)\n",
    "    X_combined = combined_data.drop(columns=['OS.time', 'OS', 'index','age_at_index','gender'])\n",
    "    \n",
    "    # Predict probabilities using the trained model\n",
    "    probabilities = model.predict_proba(X_combined)[:, 1]\n",
    "    \n",
    "    # Calculate median probability\n",
    "    median_prob = np.median(probabilities)\n",
    "    \n",
    "    # Assign survival groups based on the calculated median probability\n",
    "    combined_data['Survival_Group'] = ['Short Survival' if p >= median_prob else 'Long Survival' for p in probabilities]\n",
    "    \n",
    "    # Split the combined data back into train and test data\n",
    "    train_data['Survival_Group'] = combined_data.iloc[:len(train_data)]['Survival_Group']\n",
    "    test_data['Survival_Group'] = combined_data.iloc[len(train_data):]['Survival_Group']\n",
    "    \n",
    "    return train_data, test_data\n",
    "# Define `assign_survival_groups` function to assign survival groups based on predicted probabilities:\n",
    "# - Combine training and testing datasets.\n",
    "# - Predict survival probabilities using the trained model.\n",
    "# - Assign \"Short Survival\" or \"Long Survival\" based on the median probability.\n",
    "# - Split the combined data back into training and testing datasets.\n",
    "\n",
    "# Function to perform Kaplan-Meier analysis and plot results\n",
    "def perform_km_analysis(test_data):\n",
    "    plt.rcParams[\"font.family\"] = \"Times New Roman\"  # Set font to Times New Roman\n",
    "    plt.rcParams[\"font.size\"] = 34   # Set font size.\n",
    "\n",
    "    kmf_long = KaplanMeierFitter()\n",
    "    # Create an instance of the Kaplan-Meier Fitter for the \"Long Survival\" group.\n",
    "    # This will be used to fit and plot the survival curve for the \"Long Survival\" group.\n",
    "    kmf_short = KaplanMeierFitter()\n",
    "    # Create another instance of the Kaplan-Meier Fitter for the \"Short Survival\" group.\n",
    "    # This will be used to fit and plot the survival curve for the \"Short Survival\" group. \n",
    "    long_survival_data = test_data[test_data['Survival_Group'] == 'Long Survival']\n",
    "    short_survival_data = test_data[test_data['Survival_Group'] == 'Short Survival']\n",
    "    T_long, E_long = long_survival_data['OS.time'], long_survival_data['OS']\n",
    "    T_short, E_short = short_survival_data['OS.time'], short_survival_data['OS']\n",
    "\n",
    "    # Fit Cox Proportional Hazards model\n",
    "    df = pd.DataFrame({\n",
    "        'time': np.concatenate([T_long, T_short]), # Combine survival times from both \"Long Survival\" and \"Short Survival\" groups into a single array.\n",
    "        'event': np.concatenate([E_long, E_short]), # Combine event indicators (e.g., death or censoring) from both groups into a single array.\n",
    "        'group': ['Long'] * len(T_long) + ['Short'] * len(T_short) # Create a \"group\" column with labels \"Long\" for the \"Long Survival\" group and \"Short\" for the \"Short Survival group\".\n",
    "    })\n",
    "    cph = CoxPHFitter() # Create an instance of the Cox Proportional Hazards model, which is used to analyze the relationship between survival time and predictor variables.\n",
    "    cph.fit(df, 'time', event_col='event', formula='group')\n",
    "    # Fit the Cox model using the provided DataFrame `df`.\n",
    "    # - `time`: The column representing survival time.\n",
    "    # - `event_col`: The column indicating whether the event (e.g., death) occurred (1) or was censored (0).\n",
    "    # - `formula='group'`: Specifies that the \"group\" column (e.g., \"Long\" or \"Short\") is the predictor variable.\n",
    "\n",
    "    hr = cph.summary.loc['group[T.Short]', 'exp(coef)']\n",
    "    # Extract the hazard ratio (HR) for the \"Short Survival\" group compared to the \"Long Survival\" group.\n",
    "   # The HR indicates the relative risk of the event occurring in the \"Short Survival\" group.\n",
    "\n",
    "    ci_lower = cph.summary.loc['group[T.Short]', 'exp(coef) lower 95%'] # Extract the lower bound of the 95% confidence interval for the hazard ratio.\n",
    "    ci_upper = cph.summary.loc['group[T.Short]', 'exp(coef) upper 95%'] # Extract the upper bound of the 95% confidence interval for the hazard ratio.\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12,10))  # Increase figure size\n",
    "    kmf_long.fit(T_long, E_long, label='Long Survival').plot(ax=ax)\n",
    "    kmf_short.fit(T_short, E_short, label='Short Survival').plot(ax=ax)\n",
    "    \n",
    "    ax.grid(True, linestyle='--', linewidth=0.5)  # Add horizontal grid lines\n",
    "    ax.minorticks_on()\n",
    "    ax.grid(which='minor', linestyle=':', linewidth=0.5)  # Add minor grid lines\n",
    "\n",
    "    add_at_risk_counts(kmf_long, kmf_short, ax=ax, labels=['Long Survival', 'Short Survival'], ypos=-0.5)  # Move risk table down\n",
    "    \n",
    "    results = logrank_test(T_long, T_short, event_observed_A=E_long, event_observed_B=E_short)\n",
    "    \n",
    "    plt.title(f'p-value={results.p_value:.3f}, HR={hr:.2f} [95% CI: {ci_lower:.2f}-{ci_upper:.2f}]')\n",
    "    ax.set_ylabel('Survival Probability')  # Ensure Y-axis label is set\n",
    "    ax.set_xlabel('Time (days)')  # Hide the X-axis label by setting it to an empty string\n",
    "    plt.tight_layout()  # Adjust layout to make room for the risk table\n",
    "    plt.subplots_adjust(bottom=0.2)  # Adjust the space at the bottom for the X-axis label\n",
    "    plt.show()\n",
    "    return results\n",
    "# Define `perform_km_analysis` function to perform Kaplan-Meier survival analysis and plot results:\n",
    "# - Fit Kaplan-Meier curves for \"Long Survival\" and \"Short Survival\" groups.\n",
    "# - Fit a Cox Proportional Hazards model to calculate hazard ratio (HR) and confidence intervals.\n",
    "# - Plot Kaplan-Meier curves and add a risk table.\n",
    "\n",
    "\n",
    "# Function to calculate c-index and Brier score\n",
    "def calculate_metrics(model, test_data):\n",
    "    # Extract features and true labels\n",
    "    X_test = test_data.drop(columns=['OS.time', 'OS', 'index', 'age_at_index', 'gender', 'Survival_Group'])\n",
    "    T_test = test_data['OS.time']\n",
    "    E_test = test_data['OS']\n",
    "    \n",
    "    # Predict probabilities for the test set\n",
    "    predicted_probabilities = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate c-index\n",
    "    c_index = concordance_index(T_test, -predicted_probabilities, E_test)\n",
    "    \n",
    "    # Calculate Brier score\n",
    "    brier_score = brier_score_loss(E_test, predicted_probabilities)\n",
    "    \n",
    "    print(f\"c-index: {c_index:.3f}\")\n",
    "    print(f\"Brier score: {brier_score:.3f}\")\n",
    "    return c_index, brier_score\n",
    "# Define `calculate_metrics` function to evaluate model performance:\n",
    "# - c-index: Measures the concordance between predicted and actual survival times.\n",
    "# - Brier score: Measures the accuracy of predicted probabilities.\n",
    "\n",
    "# Main execution\n",
    "try:\n",
    "    train_data, test_data = load_data() # Load training and testing datasets.\n",
    "    X_train, y_train, X_test = prepare_data(train_data, test_data) # Prepare training and testing data.\n",
    "    model = train_classifier(X_train, y_train)  # Train the Random Forest classifier.\n",
    "    train_data, test_data = assign_survival_groups(model, train_data, test_data) # Assign survival groups based on predicted probabilities.\n",
    "    results = perform_km_analysis(test_data) # Perform Kaplan-Meier analysis and plot results.\n",
    "    c_index, brier_score = calculate_metrics(model, test_data) # Calculate c-index and Brier score\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "# Main program execution:\n",
    "# - Catch and print any errors that occur during execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBOOST\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lifelines import KaplanMeierFitter, CoxPHFitter\n",
    "from lifelines.plotting import add_at_risk_counts\n",
    "from lifelines.statistics import logrank_test\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from lifelines.utils import concordance_index\n",
    "\n",
    "# Function to load data\n",
    "def load_data():\n",
    "    train_data = pd.read_csv(\"D:/Apple/survival analysis/survival analysis/APPLE/t1+t1Gd+t2+flair/combination_survival/Total_GBM+LGG_t1+t2+t2Gd+flair_s_ICC_LASSO_survival_train.csv\")\n",
    "    test_data = pd.read_csv(\"D:/Apple/survival analysis/survival analysis/APPLE/t1+t1Gd+t2+flair/combination_survival/Total_GBM+LGG_t1+t2+t2Gd+flair_s_ICC_LASSO_survival_test.csv\")\n",
    "    return train_data, test_data\n",
    "# Define `load_data` function to load training and testing datasets from specified file paths.\n",
    "\n",
    "# Function to prepare data\n",
    "def prepare_data(train_data, test_data):\n",
    "    X_train = train_data.drop(columns=['OS.time', 'OS', 'index','age_at_index','gender'])\n",
    "    y_train = train_data['OS']\n",
    "    X_test = test_data.drop(columns=['OS.time', 'OS', 'index','age_at_index','gender'])\n",
    "    return X_train, y_train, X_test\n",
    "# Define `prepare_data` function to extract features and labels from training and testing datasets:\n",
    "# - Drop irrelevant columns (e.g., `OS.time`, `index`, etc.).\n",
    "# - Return training features, training labels, and testing features.\n",
    "\n",
    "# Define a function to train a classifier using the XGBoost algorithm.\n",
    "def train_classifier(X_train, y_train): \n",
    "    model = XGBClassifier(use_label_encoder=False)\n",
    "    # Create an instance of the XGBoost classifier.\n",
    "    # The parameter `use_label_encoder=False` disables the use of the label encoder, \n",
    "    # which is deprecated in newer versions of XGBoost.\n",
    "    model.fit(X_train, y_train)\n",
    "    # Train the XGBoost model using the training features (`X_train`) and labels (`y_train`).\n",
    "    # The `fit` method adjusts the model parameters to minimize the loss function.\n",
    "    return model\n",
    "\n",
    "# Function to predict and assign survival groups，the same as the previous one(RF)\n",
    "def assign_survival_groups(model, train_data, test_data):\n",
    "    # Combine train and test data\n",
    "    combined_data = pd.concat([train_data, test_data], axis=0)\n",
    "    X_combined = combined_data.drop(columns=['OS.time', 'OS', 'index','age_at_index','gender'])\n",
    "    \n",
    "    # Predict probabilities using the trained model\n",
    "    probabilities = model.predict_proba(X_combined)[:, 1]\n",
    "    \n",
    "    # Calculate median probability\n",
    "    median_prob = np.median(probabilities)\n",
    "    \n",
    "    # Assign survival groups based on the calculated median probability\n",
    "    combined_data['Survival_Group'] = ['Short Survival' if p >= median_prob else 'Long Survival' for p in probabilities]\n",
    "    \n",
    "    # Split the combined data back into train and test data\n",
    "    train_data['Survival_Group'] = combined_data.iloc[:len(train_data)]['Survival_Group']\n",
    "    test_data['Survival_Group'] = combined_data.iloc[len(train_data):]['Survival_Group']\n",
    "    \n",
    "    return train_data, test_data\n",
    "\n",
    "# Function to perform Kaplan-Meier analysis and plot results, the same as the previous one(RF)\n",
    "def perform_km_analysis(test_data):\n",
    "    plt.rcParams[\"font.family\"] = \"Times New Roman\"  # Set font to Times New Roman\n",
    "    plt.rcParams[\"font.size\"] = 34  \n",
    "\n",
    "    kmf_long = KaplanMeierFitter()\n",
    "    kmf_short = KaplanMeierFitter()\n",
    "    long_survival_data = test_data[test_data['Survival_Group'] == 'Long Survival']\n",
    "    short_survival_data = test_data[test_data['Survival_Group'] == 'Short Survival']\n",
    "    T_long, E_long = long_survival_data['OS.time'], long_survival_data['OS']\n",
    "    T_short, E_short = short_survival_data['OS.time'], short_survival_data['OS']\n",
    "\n",
    "    # Fit Cox Proportional Hazards model\n",
    "    df = pd.DataFrame({\n",
    "        'time': np.concatenate([T_long, T_short]),\n",
    "        'event': np.concatenate([E_long, E_short]),\n",
    "        'group': ['Long'] * len(T_long) + ['Short'] * len(T_short)\n",
    "    })\n",
    "    cph = CoxPHFitter()\n",
    "    cph.fit(df, 'time', event_col='event', formula='group')\n",
    "    hr = cph.summary.loc['group[T.Short]', 'exp(coef)']\n",
    "    ci_lower = cph.summary.loc['group[T.Short]', 'exp(coef) lower 95%']\n",
    "    ci_upper = cph.summary.loc['group[T.Short]', 'exp(coef) upper 95%']\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12,10))  # Increase figure size\n",
    "    kmf_long.fit(T_long, E_long, label='Long Survival').plot(ax=ax)\n",
    "    kmf_short.fit(T_short, E_short, label='Short Survival').plot(ax=ax)\n",
    "    \n",
    "    ax.grid(True, linestyle='--', linewidth=0.5)  # Add horizontal grid lines\n",
    "    ax.minorticks_on()\n",
    "    ax.grid(which='minor', linestyle=':', linewidth=0.5)  # Add minor grid lines\n",
    "\n",
    "    add_at_risk_counts(kmf_long, kmf_short, ax=ax, labels=['Long Survival', 'Short Survival'], ypos=-0.5)  # Move risk table down\n",
    "    \n",
    "    results = logrank_test(T_long, T_short, event_observed_A=E_long, event_observed_B=E_short)\n",
    "    \n",
    "    plt.title(f'p-value={results.p_value:.3f}, HR={hr:.2f} [95% CI: {ci_lower:.2f}-{ci_upper:.2f}]')\n",
    "    ax.set_ylabel('Survival Probability')  # Ensure Y-axis label is set\n",
    "    ax.set_xlabel('Time (days)')  # Hide the X-axis label by setting it to an empty string\n",
    "    plt.tight_layout()  # Adjust layout to make room for the risk table\n",
    "    plt.subplots_adjust(bottom=0.2)  # Adjust the space at the bottom for the X-axis label\n",
    "    plt.show()\n",
    "    return results\n",
    "def calculate_metrics(model, test_data):\n",
    "    # Extract features and true labels\n",
    "    X_test = test_data.drop(columns=['OS.time', 'OS', 'index', 'age_at_index', 'gender', 'Survival_Group'])\n",
    "    T_test = test_data['OS.time']\n",
    "    E_test = test_data['OS']\n",
    "    \n",
    "    # Predict probabilities for the test set\n",
    "    predicted_probabilities = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate c-index\n",
    "    c_index = concordance_index(T_test, -predicted_probabilities, E_test)\n",
    "    \n",
    "    # Calculate Brier score\n",
    "    brier_score = brier_score_loss(E_test, predicted_probabilities)\n",
    "    \n",
    "    print(f\"c-index: {c_index:.3f}\")\n",
    "    print(f\"Brier score: {brier_score:.3f}\")\n",
    "    return c_index, brier_score\n",
    "\n",
    "# Main execution\n",
    "try:\n",
    "    train_data, test_data = load_data()\n",
    "    X_train, y_train, X_test = prepare_data(train_data, test_data)\n",
    "    model = train_classifier(X_train, y_train)\n",
    "    train_data, test_data = assign_survival_groups(model, train_data, test_data)\n",
    "    results = perform_km_analysis(test_data)\n",
    "    # Calculate c-index and Brier score\n",
    "    c_index, brier_score = calculate_metrics(model, test_data)\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LR\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from lifelines import KaplanMeierFitter, CoxPHFitter\n",
    "from lifelines.plotting import add_at_risk_counts\n",
    "from lifelines.statistics import logrank_test\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from lifelines.utils import concordance_index\n",
    "\n",
    "# Function to load data\n",
    "def load_data():\n",
    "    train_data = pd.read_csv(\"D:/Apple/survival analysis/survival analysis/APPLE/t1+t1Gd+t2+flair/combination_survival/Total_GBM+LGG_t1+t2+t2Gd+flair_s_ICC_LASSO_survival_train.csv\")\n",
    "    test_data = pd.read_csv(\"D:/Apple/survival analysis/survival analysis/APPLE/t1+t1Gd+t2+flair/combination_survival/Total_GBM+LGG_t1+t2+t2Gd+flair_s_ICC_LASSO_survival_test.csv\")\n",
    "    return train_data, test_data\n",
    "# Define `load_data` function to load training and testing datasets from specified file paths.\n",
    "\n",
    "# Function to prepare data\n",
    "def prepare_data(train_data, test_data):\n",
    "    X_train = train_data.drop(columns=['OS.time', 'OS', 'index','age_at_index','gender'])\n",
    "    y_train = train_data['OS']\n",
    "    X_test = test_data.drop(columns=['OS.time', 'OS', 'index','age_at_index','gender'])\n",
    "    return X_train, y_train, X_test\n",
    "# Define `prepare_data` function to extract features and labels from training and testing datasets:\n",
    "# - Drop irrelevant columns (e.g., `OS.time`, `index`, etc.).\n",
    "# - Return training features, training labels, and testing features.\n",
    "\n",
    "\n",
    "# def train_classifier(X_train, y_train):\n",
    "#     model = LogisticRegression(penalty=\"l2\", solver=\"liblinear\", C=1.0, max_iter=100)\n",
    "#     model.fit(X_train, y_train)\n",
    "#     return model\n",
    "#Define 'train_classifier' function to train a logistic regression classifier:\n",
    "def train_classifier(X_train, y_train):\n",
    "    # Define the parameter grid for hyperparameter tuning\n",
    "    param_grid = {'C': [1], 'solver': ['liblinear'], 'penalty': ['l2']}\n",
    "    # - `C`: Regularization strength (smaller values specify stronger regularization).\n",
    "    # - `solver`: Optimization algorithm, 'liblinear' is suitable for small datasets.\n",
    "    # - `penalty`: Regularization type, 'l2' applies Ridge regularization.\n",
    "    # Initialize Logistic Regression\n",
    "\n",
    "    model = LogisticRegression(max_iter=100) # - `max_iter=100`: Maximum number of iterations for the solver to converge.\n",
    "    \n",
    "    # Apply GridSearchCV\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    # - `estimator`: The Logistic Regression model to be tuned.\n",
    "    # - `param_grid`: The grid of hyperparameters to search.\n",
    "    # - `cv=5`: Perform 5-fold cross-validation.\n",
    "    # - `scoring='accuracy'`: Use accuracy as the evaluation metric.\n",
    "    # - `n_jobs=-1`: Use all available CPU cores for parallel processing.\n",
    "    \n",
    "    grid_search.fit(X_train, y_train) # Fit the model to the training data and perform hyperparameter tuning.\n",
    "\n",
    "    print(\"Best parameters found: \", grid_search.best_params_) # Output the best combination of hyperparameters found during the search.\n",
    "    \n",
    "    # Return the best model\n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "# Function to predict and assign survival groups，the same as the previous one(RF)\n",
    "def assign_survival_groups(model, train_data, test_data):\n",
    "    # Combine train and test data\n",
    "    combined_data = pd.concat([train_data, test_data], axis=0)\n",
    "    X_combined = combined_data.drop(columns=['OS.time', 'OS', 'index','age_at_index','gender'])\n",
    "    \n",
    "    # Predict probabilities using the trained model\n",
    "    probabilities = model.predict_proba(X_combined)[:, 1]\n",
    "    \n",
    "    # Calculate median probability\n",
    "    median_prob = np.median(probabilities)\n",
    "    \n",
    "    # Assign survival groups based on the calculated median probability\n",
    "    combined_data['Survival_Group'] = ['Short Survival' if p >= median_prob else 'Long Survival' for p in probabilities]\n",
    "    \n",
    "    # Split the combined data back into train and test data\n",
    "    train_data['Survival_Group'] = combined_data.iloc[:len(train_data)]['Survival_Group']\n",
    "    test_data['Survival_Group'] = combined_data.iloc[len(train_data):]['Survival_Group']\n",
    "    \n",
    "    return train_data, test_data\n",
    "\n",
    "# Function to perform Kaplan-Meier analysis and plot results,the same as the previous one(RF)\n",
    "def perform_km_analysis(test_data):\n",
    "    plt.rcParams[\"font.family\"] = \"Times New Roman\"  # Set font to Times New Roman\n",
    "    plt.rcParams[\"font.size\"] = 34  \n",
    "\n",
    "    kmf_long = KaplanMeierFitter()\n",
    "    kmf_short = KaplanMeierFitter()\n",
    "    long_survival_data = test_data[test_data['Survival_Group'] == 'Long Survival']\n",
    "    short_survival_data = test_data[test_data['Survival_Group'] == 'Short Survival']\n",
    "    T_long, E_long = long_survival_data['OS.time'], long_survival_data['OS']\n",
    "    T_short, E_short = short_survival_data['OS.time'], short_survival_data['OS']\n",
    "\n",
    "    # Fit Cox Proportional Hazards model\n",
    "    df = pd.DataFrame({\n",
    "        'time': np.concatenate([T_long, T_short]),\n",
    "        'event': np.concatenate([E_long, E_short]),\n",
    "        'group': ['Long'] * len(T_long) + ['Short'] * len(T_short)\n",
    "    })\n",
    "    cph = CoxPHFitter()\n",
    "    cph.fit(df, 'time', event_col='event', formula='group')\n",
    "    hr = cph.summary.loc['group[T.Short]', 'exp(coef)']\n",
    "    ci_lower = cph.summary.loc['group[T.Short]', 'exp(coef) lower 95%']\n",
    "    ci_upper = cph.summary.loc['group[T.Short]', 'exp(coef) upper 95%']\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12,10))  # Increase figure size\n",
    "    kmf_long.fit(T_long, E_long, label='Long Survival').plot(ax=ax)\n",
    "    kmf_short.fit(T_short, E_short, label='Short Survival').plot(ax=ax)\n",
    "    \n",
    "    ax.grid(True, linestyle='--', linewidth=0.5)  # Add horizontal grid lines\n",
    "    ax.minorticks_on()\n",
    "    ax.grid(which='minor', linestyle=':', linewidth=0.5)  # Add minor grid lines\n",
    "\n",
    "    add_at_risk_counts(kmf_long, kmf_short, ax=ax, labels=['Long Survival', 'Short Survival'], ypos=-0.5)  # Move risk table down\n",
    "    \n",
    "    results = logrank_test(T_long, T_short, event_observed_A=E_long, event_observed_B=E_short)\n",
    "    \n",
    "    plt.title(f'p-value={results.p_value:.3f}, HR={hr:.2f} [95% CI: {ci_lower:.2f}-{ci_upper:.2f}]')\n",
    "    ax.set_ylabel('Survival Probability')  # Ensure Y-axis label is set\n",
    "    ax.set_xlabel('Time (days)')  # Hide the X-axis label by setting it to an empty string\n",
    "    plt.tight_layout()  # Adjust layout to make room for the risk table\n",
    "    plt.subplots_adjust(bottom=0.2)  # Adjust the space at the bottom for the X-axis label\n",
    "    plt.show()\n",
    "    # Output all p-values\n",
    "    print(\"Log-rank test p-value:\", results.p_value)\n",
    "    print(\"Cox model p-values:\")\n",
    "    print(cph.summary['p'])\n",
    "    \n",
    "    return results\n",
    "    return results\n",
    "def calculate_metrics(model, test_data): #the same as the previous one(RF)\n",
    "    # Extract features and true labels\n",
    "    X_test = test_data.drop(columns=['OS.time', 'OS', 'index', 'age_at_index', 'gender', 'Survival_Group'])\n",
    "    T_test = test_data['OS.time']\n",
    "    E_test = test_data['OS']\n",
    "    \n",
    "    # Predict probabilities for the test set\n",
    "    predicted_probabilities = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate c-index\n",
    "    c_index = concordance_index(T_test, -predicted_probabilities, E_test)\n",
    "    \n",
    "    # Calculate Brier score\n",
    "    brier_score = brier_score_loss(E_test, predicted_probabilities)\n",
    "    \n",
    "    print(f\"c-index: {c_index:.3f}\")\n",
    "    print(f\"Brier score: {brier_score:.3f}\")\n",
    "    return c_index, brier_score\n",
    "\n",
    "# Main execution,also the same as the previous one(RF)\n",
    "try:\n",
    "    train_data, test_data = load_data()\n",
    "    X_train, y_train, X_test = prepare_data(train_data, test_data)\n",
    "    model = train_classifier(X_train, y_train)\n",
    "    train_data, test_data = assign_survival_groups(model, train_data, test_data)\n",
    "    results = perform_km_analysis(test_data)\n",
    "    # Calculate c-index and Brier score\n",
    "    c_index, brier_score = calculate_metrics(model, test_data)\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from lifelines import KaplanMeierFitter, CoxPHFitter\n",
    "from lifelines.plotting import add_at_risk_counts\n",
    "from lifelines.statistics import logrank_test\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from lifelines.utils import concordance_index\n",
    "\n",
    "# Function to load data\n",
    "def load_data():\n",
    "    train_data = pd.read_csv(\"D:/Apple/survival analysis/survival analysis/APPLE/t1+t1Gd+t2+flair/combination_survival/Total_GBM+LGG_t1+t2+t2Gd+flair_s_ICC_LASSO_survival_train.csv\")\n",
    "    test_data = pd.read_csv(\"D:/Apple/survival analysis/survival analysis/APPLE/t1+t1Gd+t2+flair/combination_survival/Total_GBM+LGG_t1+t2+t2Gd+flair_s_ICC_LASSO_survival_test.csv\")\n",
    "    return train_data, test_data\n",
    "# Define `load_data` function to load training and testing datasets from specified file paths.\n",
    "\n",
    "# Function to prepare data\n",
    "def prepare_data(train_data, test_data):\n",
    "    X_train = train_data.drop(columns=['OS.time', 'OS', 'index','age_at_index','gender'])\n",
    "    y_train = train_data['OS']\n",
    "    X_test = test_data.drop(columns=['OS.time', 'OS', 'index','age_at_index','gender'])\n",
    "    return X_train, y_train, X_test\n",
    "# Define `prepare_data` function to extract features and labels from training and testing datasets:\n",
    "# - Drop irrelevant columns (e.g., `OS.time`, `index`, etc.).\n",
    "# - Return training features, training labels, and testing features.\n",
    "\n",
    "\n",
    "\n",
    "# def train_classifier(X_train, y_train):\n",
    "#     model = SVC(kernel='rbf', C=1.0, probability=True)\n",
    "#     model.fit(X_train, y_train)\n",
    "#     return \n",
    "# Function to train SVM classifier with GridSearchCV for hyperparameter tuning\n",
    "\n",
    "def train_classifier(X_train, y_train):\n",
    "    # Define the hyperparameter grid for tuning the SVM model\n",
    "    param_grid = {'C': [1], 'kernel': ['rbf'], 'probability': [True]}\n",
    "    # - `C`: Regularization parameter (higher values reduce regularization).\n",
    "    # - `kernel`: Specifies the kernel type, 'rbf' is the Radial Basis Function kernel.\n",
    "    # - `probability`: Enables probability estimates for predictions.\n",
    "    # Initialize the SVM model\n",
    "    model = SVC() # Create an instance of the Support Vector Classifier (SVC) without predefined parameters.\n",
    "    \n",
    "    # Use GridSearchCV to find the best parameters\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    # - `model`: The SVM model to be tuned.\n",
    "    # - `param_grid`: The grid of hyperparameters to search.\n",
    "    # - `cv=5`: Perform 5-fold cross-validation.\n",
    "    # - `scoring='accuracy'`: Use accuracy as the evaluation metric.\n",
    "    # - `n_jobs=-1`: Use all available CPU cores for parallel processing.\n",
    "\n",
    "    grid_search.fit(X_train, y_train)   # Fit the SVM model to the training data and perform hyperparameter tuning.\n",
    "    \n",
    "    # Output the best combination of hyperparameters found during the search\n",
    "    print(f\"Best parameters found: {grid_search.best_params_}\")\n",
    "    \n",
    "    # Return the best model\n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "\n",
    "# Function to predict and assign survival groups. This is the same as the previous one (RF)\n",
    "def assign_survival_groups(model, train_data, test_data):\n",
    "    # Combine train and test data\n",
    "    combined_data = pd.concat([train_data, test_data], axis=0)\n",
    "    X_combined = combined_data.drop(columns=['OS.time', 'OS', 'index','age_at_index','gender'])\n",
    "    \n",
    "    # Predict probabilities using the trained model\n",
    "    probabilities = model.predict_proba(X_combined)[:, 1]\n",
    "    \n",
    "    # Calculate median probability\n",
    "    median_prob = np.median(probabilities)\n",
    "    \n",
    "    # Assign survival groups based on the calculated median probability\n",
    "    combined_data['Survival_Group'] = ['Short Survival' if p >= median_prob else 'Long Survival' for p in probabilities]\n",
    "    \n",
    "    # Split the combined data back into train and test data\n",
    "    train_data['Survival_Group'] = combined_data.iloc[:len(train_data)]['Survival_Group']\n",
    "    test_data['Survival_Group'] = combined_data.iloc[len(train_data):]['Survival_Group']\n",
    "    \n",
    "    return train_data, test_data\n",
    "\n",
    "# Function to perform Kaplan-Meier analysis and plot results. This is the same as the previous one (RF)\n",
    "def perform_km_analysis(test_data):\n",
    "    plt.rcParams[\"font.family\"] = \"Times New Roman\"  # Set font to Times New Roman\n",
    "    plt.rcParams[\"font.size\"] = 34  \n",
    "\n",
    "    kmf_long = KaplanMeierFitter()\n",
    "    kmf_short = KaplanMeierFitter()\n",
    "    long_survival_data = test_data[test_data['Survival_Group'] == 'Long Survival']\n",
    "    short_survival_data = test_data[test_data['Survival_Group'] == 'Short Survival']\n",
    "    T_long, E_long = long_survival_data['OS.time'], long_survival_data['OS']\n",
    "    T_short, E_short = short_survival_data['OS.time'], short_survival_data['OS']\n",
    "\n",
    "    # Fit Cox Proportional Hazards model\n",
    "    df = pd.DataFrame({\n",
    "        'time': np.concatenate([T_long, T_short]),\n",
    "        'event': np.concatenate([E_long, E_short]),\n",
    "        'group': ['Long'] * len(T_long) + ['Short'] * len(T_short)\n",
    "    })\n",
    "    cph = CoxPHFitter()\n",
    "    cph.fit(df, 'time', event_col='event', formula='group')\n",
    "    hr = cph.summary.loc['group[T.Short]', 'exp(coef)']\n",
    "    ci_lower = cph.summary.loc['group[T.Short]', 'exp(coef) lower 95%']\n",
    "    ci_upper = cph.summary.loc['group[T.Short]', 'exp(coef) upper 95%']\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12,10))  # Increase figure size\n",
    "    kmf_long.fit(T_long, E_long, label='Long Survival').plot(ax=ax)\n",
    "    kmf_short.fit(T_short, E_short, label='Short Survival').plot(ax=ax)\n",
    "    \n",
    "    ax.grid(True, linestyle='--', linewidth=0.5)  # Add horizontal grid lines\n",
    "    ax.minorticks_on()\n",
    "    ax.grid(which='minor', linestyle=':', linewidth=0.5)  # Add minor grid lines\n",
    "\n",
    "    add_at_risk_counts(kmf_long, kmf_short, ax=ax, labels=['Long Survival', 'Short Survival'], ypos=-0.5)  # Move risk table down\n",
    "    \n",
    "    results = logrank_test(T_long, T_short, event_observed_A=E_long, event_observed_B=E_short)\n",
    "    \n",
    "    plt.title(f'p-value={results.p_value:.3f}, HR={hr:.2f} [95% CI: {ci_lower:.2f}-{ci_upper:.2f}]')\n",
    "    ax.set_ylabel('Survival Probability')  # Ensure Y-axis label is set\n",
    "    ax.set_xlabel('Time (days)')  # Hide the X-axis label by setting it to an empty string\n",
    "    plt.tight_layout()  # Adjust layout to make room for the risk table\n",
    "    plt.subplots_adjust(bottom=0.2)  # Adjust the space at the bottom for the X-axis label\n",
    "    plt.show()\n",
    "    return results\n",
    "def calculate_metrics(model, test_data):\n",
    "    # Extract features and true labels. This is the same as the previous one (RF)\n",
    "    X_test = test_data.drop(columns=['OS.time', 'OS', 'index', 'age_at_index', 'gender', 'Survival_Group'])\n",
    "    T_test = test_data['OS.time']\n",
    "    E_test = test_data['OS']\n",
    "    \n",
    "    # Predict probabilities for the test set\n",
    "    predicted_probabilities = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate c-index\n",
    "    c_index = concordance_index(T_test, -predicted_probabilities, E_test)\n",
    "    \n",
    "    # Calculate Brier score\n",
    "    brier_score = brier_score_loss(E_test, predicted_probabilities)\n",
    "    \n",
    "    print(f\"c-index: {c_index:.3f}\")\n",
    "    print(f\"Brier score: {brier_score:.3f}\")\n",
    "    return c_index, brier_score\n",
    "\n",
    "# Main execution. This is the same as the previous one (RF)\n",
    "try:\n",
    "    train_data, test_data = load_data()\n",
    "    X_train, y_train, X_test = prepare_data(train_data, test_data)\n",
    "    model = train_classifier(X_train, y_train)\n",
    "    train_data, test_data = assign_survival_groups(model, train_data, test_data)\n",
    "    results = perform_km_analysis(test_data)\n",
    "    # Calculate c-index and Brier score\n",
    "    c_index, brier_score = calculate_metrics(model, test_data)\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-GPU-apple-vscode",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
