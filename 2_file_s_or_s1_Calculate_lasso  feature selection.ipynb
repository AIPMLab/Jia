{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LassoCV\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dataFile = \"D:/Apple-paper/Radiomics/survival analysis/survival analysis/APPLE/t1+t1Gd+t2+flair/2_2_all_feature_divide_train_test/Total_GBM+LGG_flair_s_add_os_age_gender_label_train.csv\"\n",
    "data = pd.read_csv(dataFile)\n",
    "dataFile_test = \"D:/Apple-paper/Radiomics/survival analysis/survival analysis/APPLE/t1+t1Gd+t2+flair/2_2_all_feature_divide_train_test/Total_GBM+LGG_flair_s_add_os_age_gender_label_test.csv\"\n",
    "data_test = pd.read_csv(dataFile_test)\n",
    "# x = data.iloc[:, 1:]\n",
    "# y = data[\"label\"]\n",
    "# x_test = data_test.iloc[:, 1:]\n",
    "# y_test = data_test[\"label\"]\n",
    "# x.shape\n",
    "# Remove the columns OS, OS.time, age_at_index, and gender from x to prevent them from participating in the Lasso regression calculation.\n",
    "x = data.drop(columns=['index','OS', 'OS.time', 'age_at_index', 'label','gender'])\n",
    "y = data[\"label\"]  # label is used as the target variable. If it is other tasks, the target variable is replaced as appropriate.\n",
    "x_test = data_test.drop(columns=['index','OS', 'OS.time', 'age_at_index', 'label','gender'])\n",
    "y_test = data_test[\"label\"]  # label of the test set\n",
    "\n",
    "# Check the shape of x\n",
    "x.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log function, with base 10, that is, randomly select 100 numbers from lg(-10) to lg(-1).\n",
    "alphas = np.logspace(-10, -1, 100, base=10)\n",
    "alphas\n",
    "\n",
    "selector_lasso = LassoCV(alphas=alphas, cv=5, max_iter=int(1e6))\n",
    "# alphas = alphas is the array generated above, cv = 5 is 5 times cross validation\n",
    "selector_lasso.fit(x, y)  \n",
    "\n",
    "selector_lasso.alpha_  # Select the optimal a value. This value cannot be in the range of alphas (i.e., lg(-10) to lg(-1)), otherwise the boundary setting is unreasonable.\n",
    "\n",
    "selector_lasso.coef_  # Characteristic coefficient\n",
    "\n",
    "x.columns[selector_lasso.coef_ != 0]  # Select the feature coefficients that are not equal to 0 and delete the meaningless features with feature coefficients = 0\n",
    "\n",
    "x[x.columns[selector_lasso.coef_ != 0]]  # Generating DataFrame\n",
    "\n",
    "selector_lasso.intercept_  # intercept\n",
    "\n",
    "selector_lasso.mse_path_.shape  # selector_lasso.mse_path_is the error of each cross validation\n",
    "\n",
    "selector_lasso.mse_path_.mean(axis=1)  # The average of 5 errors, axis = 1 represent column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "selected_features_df = x[x.columns[selector_lasso.coef_ != 0]]  #Select features whose LASSO regression coefficient is not 0 from the training set `x` and generate a new data frame `selected_features_df`\n",
    "selected_features_test = x_test[x_test.columns[selector_lasso.coef_ != 0]] #Select features whose LASSO regression coefficient is not 0 from the test set `x_test` to generate a new data frame `selected_features_test`\n",
    "\n",
    "labels = data[[\"label\", \"OS\", \"OS.time\", \"age_at_index\", \"index\",'gender']]  # Assume the label column name is 'label', please modify it according to the actual situation\n",
    "labels_test = data_test[[\"label\", \"OS\", \"OS.time\", \"age_at_index\", \"index\",'gender']]\n",
    "\n",
    "# Merge the label column with the selected features dataframe\n",
    "selected_features_with_labels = pd.concat(\n",
    "    [selected_features_df, labels], axis=1)\n",
    "selected_features_with_labels_test = pd.concat(\n",
    "    [selected_features_test, labels_test], axis=1)\n",
    "\n",
    "# # \n",
    "# selected_features_with_labels.to_csv('D:/radiomic1/glioma/csv2/' +\n",
    "#                                      'lasso_selected_features_train_t2_s.csv', index=False)\n",
    "# selected_features_with_labels_test.to_csv(\n",
    "#     'D:/radiomic1/glioma/csv2/'+'lasso_selected_features_test_t2_s.csv', index=False)\n",
    "import os\n",
    "output_dir = 'D:/Apple-paper/Radiomics/survival analysis/survival analysis/APPLE/t1+t1Gd+t2+flair/2_3_lasso_feature_divide_train_test'\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)  #If the output directory does not exist, create it\n",
    "\n",
    "# Save the merged data frame as a CSV file\n",
    "selected_features_with_labels.to_csv(os.path.join(output_dir, 'Total_GBM+LGG_flair_s_add_os_age_gender_label_train_selsect_lasso.csv'), index=False)\n",
    "selected_features_with_labels_test.to_csv(os.path.join(output_dir, 'Total_GBM+LGG_flair_s_add_os_age_gender_label_test_selsect_lasso.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 1\n",
    "\n",
    "MSEs_mean = selector_lasso.mse_path_.mean(axis=1)  # Calculate the mean squared error (MSE) for each alpha (Lambda) in LASSO regression and store it in the variable `MSEs_mean`.\n",
    "MSEs_std = selector_lasso.mse_path_.std(axis=1)  # Calculate the standard deviation of the MSE for each alpha (Lambda) in LASSO regression and store it in the variable `MSEs_std`.\n",
    "\n",
    "plt.figure()\n",
    "plt.errorbar(selector_lasso.alphas_, MSEs_mean, yerr=MSEs_std  # The first argument represents the x-axis, the second represents the y-axis, and the third represents the error range (blue error bars).\n",
    "             , fmt=\"o\"  # Marker style for data points.\n",
    "             , ms=3  # Size of the data points.\n",
    "             , mfc=\"r\"  # Fill color of the data points (red).\n",
    "             , mec=\"r\"  # Edge color of the data points (red).\n",
    "             , ecolor=\"lightblue\"  # Color of the error bars (light blue).\n",
    "             , elinewidth=2  # Line width of the error bars.\n",
    "             , capsize=4  # Length of the error bar caps.\n",
    "             , capthick=1  # Thickness of the error bar caps.\n",
    "             )\n",
    "plt.semilogx()  # Plot the x-axis on a logarithmic scale.\n",
    "plt.axvline(selector_lasso.alpha_, color=\"black\",\n",
    "            ls=\"--\")  # Draw a vertical dashed line at the alpha (Lambda) corresponding to the minimum MSE (optimal Lambda).\n",
    "plt.xlabel(\"Lambda\")  # Label for the x-axis.\n",
    "plt.ylabel(\"MSE\")  # Label for the y-axis.\n",
    "plt.show()  # Display the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = np.abs(selector_lasso.coef_)\n",
    "# Calculate the absolute values of the LASSO regression coefficients to represent feature importance.\n",
    "\n",
    "# Create a DataFrame containing feature names and their importance\n",
    "features_df = pd.DataFrame({\n",
    "    'Feature Name': x.columns,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "# Save the complete list of feature importances to a CSV file\n",
    "features_df.to_csv('D:/Apple-paper/Radiomics/survival analysis/survival analysis/APPLE/t1+t1Gd+t2+flair/2_3_lasso_feature_divide_train_test/flair/flair_lasso_csv/flair_s_Lasso_feature_importances.csv', index=False)\n",
    "\n",
    "# Sort features by importance and select the top 10\n",
    "sorted_features_df = features_df.sort_values(by='Importance', ascending=False).head(10)\n",
    "\n",
    "# Plot the top 10 important features\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(sorted_features_df['Feature Name'], sorted_features_df['Importance'])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Feature Name')\n",
    "plt.title('Top 10 Important Features')\n",
    "plt.tight_layout()\n",
    "plt.gca().invert_yaxis()  # Invert the y-axis to display the most important feature at the top\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 2\n",
    "coefs = selector_lasso.path(x, y, alphas=alphas, max_iter=1e6)[1].T\n",
    "# Use the LASSO path method to compute the regression coefficient paths for different alpha (Lambda) values.\n",
    "# `selector_lasso.path` returns a tuple, where the second element is the coefficient matrix (each column corresponds to an alpha value).\n",
    "# `.T` transposes the matrix so that each row corresponds to the coefficient changes of a feature.\n",
    "\n",
    "plt.figure()\n",
    "plt.semilogx(selector_lasso.alphas_, coefs, '-')\n",
    "# Plot the LASSO regression coefficient paths.\n",
    "# The x-axis represents alpha (Lambda) values (logarithmic scale), and the y-axis represents the corresponding coefficients.\n",
    "# Each line represents the coefficient changes of a feature, with a solid line style.\n",
    "\n",
    "plt.axvline(selector_lasso.alpha_, color='black', ls=\"--\")\n",
    "# Draw a vertical dashed line at the alpha (Lambda) value selected by the LASSO model, with black color.\n",
    "\n",
    "plt.xlabel('Lambda')  # Set the label for the x-axis as \"Lambda\".\n",
    "plt.ylabel('Coefficients')  # Set the label for the y-axis as \"Coefficients\".\n",
    "plt.show()  # Display the plot."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
